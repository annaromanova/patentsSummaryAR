{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "northern-spanking",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "import xml.etree.ElementTree as et\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "separated-electron",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "class Patent:\n",
    "    def __init__(self, patent_id):\n",
    "        self.patentNumber = patent_id\n",
    "        self.__process_xml()\n",
    "        #Extract epitope information\n",
    "        self.__extract_epitope_info()\n",
    "      \n",
    "        \n",
    "    def __process_xml(self):\n",
    "        tree = et.parse(self.patentNumber + '.xml')\n",
    "        root = tree.getroot()\n",
    "        logger.info(\"in __process_xml\")\n",
    "        self.patentName = root.find('.//invention-title').text\n",
    "        self.patentDate = root.find('.//publication-reference').find('.//date').text\n",
    "        self.inventors = [el.find('.//first-name').text + ' ' + \n",
    "                            el.find('.//last-name').text\n",
    "                            for el in root.findall('.//inventor')]\n",
    "        self.abstract = ' '.join([' '.join(el.itertext()) \n",
    "                            for el in root.findall('.//abstract')])\n",
    "        self.description = ' '.join([' '.join(el.itertext()) \n",
    "                            for el in root.findall('.//description')])\n",
    "        self.claims = [' '.join(el.itertext()) \n",
    "                            for el in root.findall('.//claim')]\n",
    "        self.patentAssignees = [el.find('.//orgname').text \n",
    "                            for el in root.findall('.//assignee')]\n",
    "        #self.applicants = [el.find('.//orgname').text \n",
    "                                #for el in root.findall('.//us-applicant')]\n",
    "        self.examiners = root.find('.//primary-examiner').find('.//first-name').text + ' ' + root.find('.//primary-examiner').find('.//last-name').text\n",
    "        self.claimsCount = len(self.claims)\n",
    "        self.appNumber = root.find('.//application-reference').find('.//doc-number').text\n",
    "        self.appDate = root.find('.//application-reference').find('.//date').text\n",
    "        \n",
    "    \n",
    "    #Extract epitope information\n",
    "    def __extract_epitope_info(self):  \n",
    "        #US9574011\n",
    "        bindingString = r'''([^.]*?antibody(.*)binds(.*)residues[^.]*\\.)'''     \n",
    "        #US8829165\n",
    "        #bindingString1 = r'''([^.]*?antibody(.*)binds(.*)residues[^.]*\\.)'''   \n",
    "        #US8859741\n",
    "        #bindingString2 = r'''([^.]*?antibody(.*)binds(.*)residues[^.]*\\.)''' \n",
    "        #US8563698\n",
    "        #bindingString3 = r'''([^.]*?antibody(.*)binds(.*)residues[^.]*\\.)''' \n",
    "        #US10023654\n",
    "        bindingString4 = r'''([^.]*?antibody(.*)binds(.*)residue[^.]*\\.)'''\n",
    "        \n",
    "        #Regex\n",
    "        bindingPattern = [re.compile(p) for p in [bindingString, bindingString4]]\n",
    "\n",
    "        #claimedResidues array of dictionaries\n",
    "        self.claimedResidues = []\n",
    "        keysForSequences = [\"seqNoId\", \"values\"]\n",
    "        keysForValues = [\"num\", \"code\"]\n",
    "        \n",
    "        lines = iter(self.claims)\n",
    "        \n",
    "        #Claimed as string\n",
    "        for claimed in lines:\n",
    "                    \n",
    "            #Find the required sentence with epitope info\n",
    "            sentenceToEvaluate = ''\n",
    "            for regex in bindingPattern:\n",
    "                if re.findall(regex, claimed):\n",
    "                    sentenceToEvaluate = re.findall(regex, claimed)\n",
    "\n",
    "            #If pattern not found - return\n",
    "            if not sentenceToEvaluate:\n",
    "                next(lines, None)\n",
    "                continue\n",
    "            \n",
    "            sequencesDict = dict.fromkeys(keysForSequences)\n",
    "\n",
    "            sentenceToEvaluate = ','.join(str(v) for v in sentenceToEvaluate)\n",
    "\n",
    "            #Extract Seq ID\n",
    "            extractedSeqID = ''.join(sentenceToEvaluate)\n",
    "            if re.search(r'\\bresidues\\b', extractedSeqID):\n",
    "                extractedSeqID = extractedSeqID.split(\"SEQ ID NO:\")[1].split(\".\")[0].strip()\n",
    "                extractedSeqID = extractedSeqID.split(\",\")[0].strip()\n",
    "            else:\n",
    "                extractedSeqID = extractedSeqID.split(\"(SEQ ID NO:\")[1].split(\").\")[0].strip()\n",
    "                \n",
    "            listings = extractedSeqID.split()\n",
    "            for l in listings:\n",
    "                if l.isdigit():\n",
    "                    sequencesDict[\"seqNoId\"] = l\n",
    "\n",
    "\n",
    "            sequencesDict[\"values\"] = []\n",
    "\n",
    "            #Extract string with residues info\n",
    "            extractedString = ''.join(sentenceToEvaluate)\n",
    "            if re.search(r'\\bresidues\\b', extractedString):\n",
    "                extractedString = extractedString.split(\"residues\")[1].split(\"SEQ ID\")[0]\n",
    "            else:\n",
    "                extractedString = extractedString.split(\"residue\")[1].split(\"SEQ ID\")[0]\n",
    "            words = extractedString.split()\n",
    "            for i in words:\n",
    "                i = i.replace(',','')\n",
    "                #if punctuation\n",
    "                if i in string.punctuation:\n",
    "                    i = i.replace(':','')     \n",
    "                #if range of sequences\n",
    "                elif i.find(\"-\") != -1:\n",
    "                    rangeList = i.split(\"-\")\n",
    "                    for n in range(int(rangeList[0]), int(rangeList[-1]) + 1):\n",
    "                        valuesDict = dict.fromkeys(keysForValues)\n",
    "                        valuesDict[\"num\"] = int(n)\n",
    "                        sequencesDict[\"values\"].append(valuesDict)    \n",
    "                #if mix of letters and digits\n",
    "                elif (i.isalpha() == False) and (i.isdigit() == False) and (len(i) < 5 ):\n",
    "                    i = i[1:]\n",
    "                    valuesDict = dict.fromkeys(keysForValues)\n",
    "                    valuesDict[\"num\"] = int(i)\n",
    "                    sequencesDict[\"values\"].append(valuesDict) \n",
    "                #if digital\n",
    "                elif i.isdigit():\n",
    "                    valuesDict = dict.fromkeys(keysForValues)\n",
    "                    valuesDict[\"num\"] = int(i)\n",
    "                    sequencesDict[\"values\"].append(valuesDict) \n",
    "                   \n",
    "            self.claimedResidues.append(sequencesDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "expanded-speed",
   "metadata": {},
   "outputs": [],
   "source": [
    "patent = Patent(\"US8829165B2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "southwest-concern",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'seqNoId': '3',\n",
       "  'values': [{'num': 153, 'code': None},\n",
       "   {'num': 154, 'code': None},\n",
       "   {'num': 155, 'code': None},\n",
       "   {'num': 194, 'code': None},\n",
       "   {'num': 238, 'code': None},\n",
       "   {'num': 239, 'code': None},\n",
       "   {'num': 369, 'code': None},\n",
       "   {'num': 372, 'code': None},\n",
       "   {'num': 374, 'code': None},\n",
       "   {'num': 375, 'code': None},\n",
       "   {'num': 377, 'code': None},\n",
       "   {'num': 378, 'code': None},\n",
       "   {'num': 379, 'code': None},\n",
       "   {'num': 380, 'code': None},\n",
       "   {'num': 381, 'code': None}]},\n",
       " {'seqNoId': '3',\n",
       "  'values': [{'num': 153, 'code': None},\n",
       "   {'num': 154, 'code': None},\n",
       "   {'num': 155, 'code': None},\n",
       "   {'num': 194, 'code': None},\n",
       "   {'num': 238, 'code': None},\n",
       "   {'num': 239, 'code': None},\n",
       "   {'num': 369, 'code': None},\n",
       "   {'num': 372, 'code': None},\n",
       "   {'num': 374, 'code': None},\n",
       "   {'num': 375, 'code': None},\n",
       "   {'num': 377, 'code': None},\n",
       "   {'num': 378, 'code': None},\n",
       "   {'num': 379, 'code': None},\n",
       "   {'num': 380, 'code': None},\n",
       "   {'num': 381, 'code': None}]},\n",
       " {'seqNoId': '3',\n",
       "  'values': [{'num': 153, 'code': None},\n",
       "   {'num': 154, 'code': None},\n",
       "   {'num': 155, 'code': None},\n",
       "   {'num': 194, 'code': None},\n",
       "   {'num': 238, 'code': None},\n",
       "   {'num': 239, 'code': None},\n",
       "   {'num': 369, 'code': None},\n",
       "   {'num': 372, 'code': None},\n",
       "   {'num': 374, 'code': None},\n",
       "   {'num': 375, 'code': None},\n",
       "   {'num': 377, 'code': None},\n",
       "   {'num': 378, 'code': None},\n",
       "   {'num': 379, 'code': None},\n",
       "   {'num': 380, 'code': None},\n",
       "   {'num': 381, 'code': None}]},\n",
       " {'seqNoId': '3',\n",
       "  'values': [{'num': 153, 'code': None},\n",
       "   {'num': 154, 'code': None},\n",
       "   {'num': 155, 'code': None},\n",
       "   {'num': 194, 'code': None},\n",
       "   {'num': 238, 'code': None},\n",
       "   {'num': 239, 'code': None},\n",
       "   {'num': 369, 'code': None},\n",
       "   {'num': 372, 'code': None},\n",
       "   {'num': 374, 'code': None},\n",
       "   {'num': 375, 'code': None},\n",
       "   {'num': 377, 'code': None},\n",
       "   {'num': 378, 'code': None},\n",
       "   {'num': 379, 'code': None},\n",
       "   {'num': 380, 'code': None},\n",
       "   {'num': 381, 'code': None}]},\n",
       " {'seqNoId': '3',\n",
       "  'values': [{'num': 153, 'code': None},\n",
       "   {'num': 154, 'code': None},\n",
       "   {'num': 155, 'code': None},\n",
       "   {'num': 194, 'code': None},\n",
       "   {'num': 238, 'code': None},\n",
       "   {'num': 239, 'code': None},\n",
       "   {'num': 369, 'code': None},\n",
       "   {'num': 372, 'code': None},\n",
       "   {'num': 374, 'code': None},\n",
       "   {'num': 375, 'code': None},\n",
       "   {'num': 377, 'code': None},\n",
       "   {'num': 378, 'code': None},\n",
       "   {'num': 379, 'code': None},\n",
       "   {'num': 380, 'code': None},\n",
       "   {'num': 381, 'code': None}]}]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patent.claimedResidues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "elementary-michigan",
   "metadata": {},
   "outputs": [],
   "source": [
    "patent1 = Patent(\"8828405\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "covered-matter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patent1.claimedResidues"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
